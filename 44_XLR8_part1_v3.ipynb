{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AFML Part 1 - Team 44_XLR8 (v3 - AGGRESSIVE)\n",
        "## New Strategy: Predict NOISE instead of CLEAN\n",
        "\n",
        "**Key Insight**: `clean = noisy - noise` is easier to learn!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"‚úÖ M2 GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"‚úÖ CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"‚ö†Ô∏è  CPU\")\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading...\")\n",
        "train_clean = pd.read_csv('train-part1-clean.csv').values.astype(np.float32)\n",
        "train_noise = pd.read_csv('train-part1-noise.csv').values.astype(np.float32)\n",
        "test_data = pd.read_csv('test-part1.csv').values.astype(np.float32)\n",
        "\n",
        "print(f\"Clean: {train_clean.shape}\")\n",
        "print(f\"Noisy: {train_noise.shape}\")\n",
        "print(f\"Test: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NEW APPROACH: Predict NOISE, not CLEAN!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_noise, train_clean, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# Calculate NOISE (this is what we'll predict!)\n",
        "noise_train = X_train - y_train  # noise = noisy - clean\n",
        "noise_val = X_val - y_val\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")\n",
        "print(f\"Noise range: [{noise_train.min():.4f}, {noise_train.max():.4f}]\")\n",
        "\n",
        "# To tensors - NO NORMALIZATION\n",
        "X_train_t = torch.FloatTensor(X_train)\n",
        "noise_train_t = torch.FloatTensor(noise_train)  # Predict noise!\n",
        "X_val_t = torch.FloatTensor(X_val)\n",
        "noise_val_t = torch.FloatTensor(noise_val)\n",
        "test_t = torch.FloatTensor(test_data)\n",
        "\n",
        "print(\"‚úì Predicting NOISE (residual learning)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wider & Deeper Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NoisePredictor(nn.Module):\n",
        "    def __init__(self, input_dim=20):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            \n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            \n",
        "            nn.Linear(2048, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            \n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            \n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            \n",
        "            nn.Linear(512, input_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "print(\"Creating 7 models (more diversity)...\")\n",
        "models = [NoisePredictor().to(device) for _ in range(7)]\n",
        "print(f\"Params per model: {sum(p.numel() for p in models[0].parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8192\n",
        "NUM_EPOCHS = 150\n",
        "LR = 0.0001  # Lower LR for stability\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train_t, noise_train_t),  # Predict noise!\n",
        "    batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    TensorDataset(X_val_t, noise_val_t),\n",
        "    batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
        ")\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizers = [optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-6) for model in models]\n",
        "schedulers = [optim.lr_scheduler.CosineAnnealingLR(opt, T_max=NUM_EPOCHS, eta_min=1e-7) for opt in optimizers]\n",
        "\n",
        "print(f\"Batches/epoch: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_val_losses = [float('inf')] * 7\n",
        "patience_counters = [0] * 7\n",
        "MAX_PATIENCE = 30\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Train\n",
        "    for model in models:\n",
        "        model.train()\n",
        "    \n",
        "    train_losses = [0] * 7\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for X_batch, noise_batch in pbar:\n",
        "        X_batch = X_batch.to(device)\n",
        "        noise_batch = noise_batch.to(device)\n",
        "        \n",
        "        for i, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
        "            pred_noise = model(X_batch)\n",
        "            loss = criterion(pred_noise, noise_batch)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_losses[i] += loss.item()\n",
        "        \n",
        "        pbar.set_postfix({'loss': f'{np.mean(train_losses) / (pbar.n + 1):.6f}'})\n",
        "    \n",
        "    train_losses = [tl / len(train_loader) for tl in train_losses]\n",
        "    \n",
        "    # Validate\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "    \n",
        "    val_losses = [0] * 7\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X_batch, noise_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            noise_batch = noise_batch.to(device)\n",
        "            \n",
        "            for i, model in enumerate(models):\n",
        "                pred_noise = model(X_batch)\n",
        "                loss = criterion(pred_noise, noise_batch)\n",
        "                val_losses[i] += loss.item()\n",
        "    \n",
        "    val_losses = [vl / len(val_loader) for vl in val_losses]\n",
        "    \n",
        "    # Schedulers\n",
        "    for scheduler in schedulers:\n",
        "        scheduler.step()\n",
        "    \n",
        "    # Save\n",
        "    saved = []\n",
        "    for i, (model, val_loss) in enumerate(zip(models, val_losses)):\n",
        "        if val_loss < best_val_losses[i]:\n",
        "            best_val_losses[i] = val_loss\n",
        "            torch.save(model.state_dict(), f'model_{i}.pth')\n",
        "            patience_counters[i] = 0\n",
        "            saved.append(i)\n",
        "        else:\n",
        "            patience_counters[i] += 1\n",
        "    \n",
        "    avg_train = np.mean(train_losses)\n",
        "    avg_val = np.mean(val_losses)\n",
        "    \n",
        "    if saved:\n",
        "        print(f\"‚úì Epoch {epoch+1} - Train: {avg_train:.6f}, Val: {avg_val:.6f} [SAVED: {saved}]\")\n",
        "    elif (epoch+1) % 10 == 0:\n",
        "        print(f\"  Epoch {epoch+1} - Train: {avg_train:.6f}, Val: {avg_val:.6f}\")\n",
        "    \n",
        "    if all(p >= MAX_PATIENCE for p in patience_counters):\n",
        "        print(f\"\\nEarly stop at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nBest val losses: {[f'{v:.6f}' for v in best_val_losses]}\")\n",
        "print(f\"Average: {np.mean(best_val_losses):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict: noise ‚Üí clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, model in enumerate(models):\n",
        "    model.load_state_dict(torch.load(f'model_{i}.pth'))\n",
        "    model.eval()\n",
        "\n",
        "print(\"Predicting noise, then subtracting...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_t_device = test_t.to(device)\n",
        "    X_val_t_device = X_val_t.to(device)\n",
        "    \n",
        "    # Predict noise with each model\n",
        "    test_noise_preds = [model(test_t_device).cpu().numpy() for model in models]\n",
        "    val_noise_preds = [model(X_val_t_device).cpu().numpy() for model in models]\n",
        "    \n",
        "    # Average noise predictions\n",
        "    test_noise = np.mean(test_noise_preds, axis=0)\n",
        "    val_noise = np.mean(val_noise_preds, axis=0)\n",
        "\n",
        "# Subtract noise to get clean!\n",
        "test_pred = test_data - test_noise  # clean = noisy - noise\n",
        "val_pred = X_val - val_noise\n",
        "\n",
        "print(\"‚úì Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = np.mean((y_val - val_pred) ** 2)\n",
        "variance = np.var(y_val)\n",
        "nmse = mse / variance\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"VALIDATION NMSE: {nmse:.6f}\")\n",
        "print(f\"Target: < 0.3\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "if nmse < 0.3:\n",
        "    print(f\"üéâ SUCCESS! NMSE < 0.3!\")\n",
        "elif nmse < 0.5:\n",
        "    print(f\"‚ö†Ô∏è  Close! NMSE = {nmse:.4f}\")\n",
        "else:\n",
        "    print(f\"‚ùå NMSE = {nmse:.4f}\")\n",
        "\n",
        "print(f\"\\nMSE: {mse:.8f}\")\n",
        "print(f\"Variance: {variance:.8f}\")\n",
        "print(f\"Avg Val Loss (noise): {np.mean(best_val_losses):.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(test_pred)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"‚úì Saved: submission.csv\")\n",
        "print(f\"Shape: {submission.shape}\")\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(20):\n",
        "    plt.scatter(y_val[:500, i], val_pred[:500, i], alpha=0.5, s=2)\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title(f'NMSE={nmse:.4f}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "errors = np.abs(y_val - val_pred)\n",
        "plt.hist(errors.flatten(), bins=100, alpha=0.7)\n",
        "plt.xlabel('Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.yscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal NMSE: {nmse:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## v3 Key Changes:\n",
        "\n",
        "1. ‚úÖ **Predicts NOISE instead of CLEAN** (residual learning)\n",
        "2. ‚úÖ **7 models** (more diversity)\n",
        "3. ‚úÖ **Wider network** (2048 units)\n",
        "4. ‚úÖ **Deeper** (6 layers)\n",
        "5. ‚úÖ **Lower LR** (0.0001 for stability)\n",
        "6. ‚úÖ **Cosine annealing** (smooth decay)\n",
        "\n",
        "**Why predicting noise works better:**\n",
        "- Noise has simpler patterns than clean weights\n",
        "- Network learns to identify and remove noise\n",
        "- Formula: `clean = noisy - predicted_noise`\n",
        "\n",
        "**Expected: NMSE 0.15-0.25** ‚úÖ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
