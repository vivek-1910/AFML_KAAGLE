{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AFML Part 2 - Team 44_XLR8 (OPTIMIZED)\n",
        "## LSTM Translation: Encoded â†’ English\n",
        "\n",
        "**Target**: Val Loss < 1.0 for good translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"âœ… M2 GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"âœ… CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"âš ï¸  CPU\")\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CharLSTMTranslator(nn.Module):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, emb_size=64, hidden_size=128, num_layers=1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(input_vocab_size, emb_size, padding_idx=0)\n",
        "        self.tgt_embedding = nn.Embedding(output_vocab_size, emb_size, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_len, emb_size)\n",
        "        self.encoder = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.decoder = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
        "        \n",
        "    def forward(self, src, tgt):\n",
        "        batch_size, seq_len = src.size()\n",
        "        pos_idx = torch.arange(seq_len, device=src.device).unsqueeze(0).repeat(batch_size, 1)\n",
        "        pos_idx = torch.clamp(pos_idx, max=511)\n",
        "        pos_embedded = self.pos_embedding(pos_idx)\n",
        "        embedded_src = self.src_embedding(src) + pos_embedded\n",
        "        _, (hidden, cell) = self.encoder(embedded_src)\n",
        "        embedded_tgt = self.tgt_embedding(tgt)\n",
        "        outputs, _ = self.decoder(embedded_tgt, (hidden, cell))\n",
        "        logits = self.fc(outputs)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Denoised Weights from Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_from_matrix(model, weights_matrix, original_len):\n",
        "    weights_matrix = torch.tensor(weights_matrix, dtype=torch.float32)\n",
        "    flat_weights = weights_matrix.reshape(-1)[:original_len]\n",
        "    offset = 0\n",
        "    for p in model.parameters():\n",
        "        numel = p.numel()\n",
        "        new_data = flat_weights[offset : offset + numel].view_as(p)\n",
        "        p.data.copy_(new_data)\n",
        "        offset += numel\n",
        "    print(f\"âœ“ Loaded {offset} parameters\")\n",
        "    return model\n",
        "\n",
        "print(\"Loading denoised weights from Part 1...\")\n",
        "df_weights = pd.read_csv(\"submission.csv\").to_numpy()\n",
        "model = CharLSTMTranslator(input_vocab_size=73, output_vocab_size=96)\n",
        "model = load_model_from_matrix(model, df_weights, 254624)\n",
        "model = model.to(device)\n",
        "print(\"âœ“ Model initialized with Part 1 weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train-part2.csv\")\n",
        "encoded_texts = df_train['encoded_text'].tolist()\n",
        "english_texts = df_train['text'].tolist()\n",
        "print(f\"Loaded {len(encoded_texts)} training pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_encoded_chars = set(''.join(encoded_texts))\n",
        "all_english_chars = set(''.join(english_texts))\n",
        "\n",
        "encoded_vocab = {c: i+1 for i, c in enumerate(sorted(all_encoded_chars))}\n",
        "encoded_vocab['<PAD>'] = 0\n",
        "\n",
        "english_vocab = {c: i+1 for i, c in enumerate(sorted(all_english_chars))}\n",
        "english_vocab['<PAD>'] = 0\n",
        "\n",
        "rev_english_vocab = {i: c for c, i in english_vocab.items()}\n",
        "\n",
        "sos_token = 71\n",
        "eos_token = 70\n",
        "\n",
        "print(f\"Encoded vocab: {len(encoded_vocab)}, English vocab: {len(english_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset with Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_seq(texts, vocab):\n",
        "    return [[vocab.get(c, 0) for c in t] for t in texts]\n",
        "\n",
        "encoded_seqs = text_to_seq(encoded_texts, encoded_vocab)\n",
        "english_seqs = text_to_seq(english_texts, english_vocab)\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_seqs, tgt_seqs, sos_token, eos_token, max_len=512):\n",
        "        self.src_seqs = src_seqs\n",
        "        self.tgt_seqs = tgt_seqs\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.src_seqs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        src_seq = self.src_seqs[idx][:self.max_len]\n",
        "        tgt_seq = self.tgt_seqs[idx][:self.max_len-2]\n",
        "        src = torch.LongTensor(src_seq)\n",
        "        tgt = torch.LongTensor([self.sos_token] + tgt_seq + [self.eos_token])\n",
        "        return src, tgt\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "dataset = TranslationDataset(encoded_seqs, english_seqs, sos_token, eos_token)\n",
        "train_size = int(0.95 * len(dataset))  # More training data\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)  # Larger batch\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training with Optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 30  # More epochs\n",
        "LEARNING_RATE = 0.002  # Higher LR\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)  # AdamW\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)  # Cosine\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "        \n",
        "        logits = model(src, tgt_input)\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_output.reshape(-1))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)  # Tighter clipping\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "            logits = model(src, tgt_input)\n",
        "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_output.reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 0\n",
        "MAX_PATIENCE = 10\n",
        "\n",
        "print(\"\\nStarting training...\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = validate(model, val_loader)\n",
        "    \n",
        "    scheduler.step()\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_translation.pth')\n",
        "        patience = 0\n",
        "        print(f\"âœ“ Epoch {epoch+1}/{NUM_EPOCHS} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, LR: {lr:.6f} [SAVED]\")\n",
        "    else:\n",
        "        patience += 1\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print(f\"  Epoch {epoch+1}/{NUM_EPOCHS} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, LR: {lr:.6f}\")\n",
        "    \n",
        "    if patience >= MAX_PATIENCE:\n",
        "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Best val loss: {best_val_loss:.4f}\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "if best_val_loss < 1.0:\n",
        "    print(\"ðŸŽ‰ Excellent! Val loss < 1.0\")\n",
        "elif best_val_loss < 2.0:\n",
        "    print(\"âœ… Good! Val loss < 2.0\")\n",
        "else:\n",
        "    print(\"âš ï¸  Val loss > 2.0 - Part 1 weights may be noisy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate(model, src_text, encoded_vocab, rev_english_vocab, sos_token, eos_token, max_len=512):\n",
        "    model.eval()\n",
        "    src_seq = [encoded_vocab.get(c, 0) for c in src_text]\n",
        "    src_tensor = torch.LongTensor(src_seq).unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        batch_size, seq_len = src_tensor.size()\n",
        "        pos_idx = torch.arange(seq_len, device=device).unsqueeze(0)\n",
        "        pos_idx = torch.clamp(pos_idx, max=511)\n",
        "        pos_embedded = model.pos_embedding(pos_idx)\n",
        "        embedded_src = model.src_embedding(src_tensor) + pos_embedded\n",
        "        _, (hidden, cell) = model.encoder(embedded_src)\n",
        "    \n",
        "    decoded = [sos_token]\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.LongTensor([decoded]).to(device)\n",
        "        with torch.no_grad():\n",
        "            embedded_tgt = model.tgt_embedding(tgt_tensor)\n",
        "            outputs, (hidden, cell) = model.decoder(embedded_tgt, (hidden, cell))\n",
        "            logits = model.fc(outputs)\n",
        "        \n",
        "        next_token = logits[0, -1].argmax().item()\n",
        "        if next_token == eos_token:\n",
        "            break\n",
        "        decoded.append(next_token)\n",
        "    \n",
        "    return ''.join([rev_english_vocab.get(i, '') for i in decoded[1:] if i != 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Training Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_translation.pth'))\n",
        "\n",
        "print(\"\\nTesting on training examples:\\n\")\n",
        "for i in range(5):\n",
        "    enc = encoded_texts[i][:60]\n",
        "    exp = english_texts[i][:60]\n",
        "    pred = translate(model, encoded_texts[i], encoded_vocab, rev_english_vocab, sos_token, eos_token)\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Encoded:  {enc}...\")\n",
        "    print(f\"Expected: {exp}...\")\n",
        "    print(f\"Predicted: {pred[:60]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Translate Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('test-part2.txt', 'r', encoding='utf-8') as f:\n",
        "    test_phrases = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(f\"\\nTranslating {len(test_phrases)} test phrases...\\n\")\n",
        "\n",
        "translations = []\n",
        "for i, phrase in enumerate(tqdm(test_phrases, desc=\"Translating\")):\n",
        "    translation = translate(model, phrase, encoded_vocab, rev_english_vocab, sos_token, eos_token)\n",
        "    translations.append(translation)\n",
        "\n",
        "# Show first 5\n",
        "print(\"\\nFirst 5 translations:\")\n",
        "for i in range(min(5, len(translations))):\n",
        "    print(f\"{i+1}. {translations[i][:80]}\")\n",
        "\n",
        "# Save\n",
        "with open('44_XLR8_part2.txt', 'w', encoding='utf-8') as f:\n",
        "    for t in translations:\n",
        "        f.write(t + '\\n')\n",
        "\n",
        "print(f\"\\nâœ“ Saved: 44_XLR8_part2.txt ({len(translations)} translations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Optimizations in Part 2:**\n",
        "1. âœ… More training data (95% vs 90%)\n",
        "2. âœ… Larger batch size (64 vs 32)\n",
        "3. âœ… Higher learning rate (0.002 vs 0.001)\n",
        "4. âœ… AdamW optimizer (better than Adam)\n",
        "5. âœ… Cosine annealing (better than ReduceLROnPlateau)\n",
        "6. âœ… More epochs (30 vs 15)\n",
        "7. âœ… Tighter gradient clipping (0.5 vs 1.0)\n",
        "8. âœ… Early stopping\n",
        "\n",
        "**Expected Results:**\n",
        "- With good Part 1 (NMSE < 0.3): Val loss 0.5-0.8 âœ…\n",
        "- With okay Part 1 (NMSE ~0.6): Val loss 1.5-2.5 âš ï¸\n",
        "\n",
        "**Next Steps:**\n",
        "1. Submit `44_XLR8_part2.txt`\n",
        "2. Share notebook with TAs"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
