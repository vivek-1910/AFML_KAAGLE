{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AFML Hackathon Part 2 - Team 44_XLR8\n",
        "## LSTM Translation: Encoded Text → English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (if using Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import os\n",
        "    os.chdir('/content/drive/MyDrive/AFML_KAAGLE')  # Adjust path\n",
        "    print(\"✓ Running on Google Colab\")\n",
        "except:\n",
        "    print(\"✓ Running locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CharLSTMTranslator(nn.Module):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, emb_size=64, hidden_size=128, num_layers=1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(input_vocab_size, emb_size, padding_idx=0)\n",
        "        self.tgt_embedding = nn.Embedding(output_vocab_size, emb_size, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_len, emb_size)\n",
        "        self.encoder = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.decoder = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
        "        \n",
        "    def forward(self, src, tgt):\n",
        "        batch_size, seq_len = src.size()\n",
        "        pos_idx = torch.arange(seq_len, device=src.device).unsqueeze(0).repeat(batch_size, 1)\n",
        "        pos_idx = torch.clamp(pos_idx, max=511)\n",
        "        pos_embedded = self.pos_embedding(pos_idx)\n",
        "        embedded_src = self.src_embedding(src) + pos_embedded\n",
        "        _, (hidden, cell) = self.encoder(embedded_src)\n",
        "        embedded_tgt = self.tgt_embedding(tgt)\n",
        "        outputs, _ = self.decoder(embedded_tgt, (hidden, cell))\n",
        "        logits = self.fc(outputs)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Denoised Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_from_matrix(model, weights_matrix, original_len):\n",
        "    weights_matrix = torch.tensor(weights_matrix, dtype=torch.float32)\n",
        "    flat_weights = weights_matrix.reshape(-1)[:original_len]\n",
        "    offset = 0\n",
        "    for p in model.parameters():\n",
        "        numel = p.numel()\n",
        "        new_data = flat_weights[offset : offset + numel].view_as(p)\n",
        "        p.data.copy_(new_data)\n",
        "        offset += numel\n",
        "    print(f\"✓ Loaded {offset} parameters\")\n",
        "    return model\n",
        "\n",
        "df_weights = pd.read_csv(\"submission.csv\").to_numpy()\n",
        "model = CharLSTMTranslator(input_vocab_size=73, output_vocab_size=96)\n",
        "model = load_model_from_matrix(model, df_weights, 254624)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train-part2.csv\")\n",
        "encoded_texts = df_train['encoded_text'].tolist()\n",
        "english_texts = df_train['text'].tolist()\n",
        "print(f\"Loaded {len(encoded_texts)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_encoded_chars = set(''.join(encoded_texts))\n",
        "all_english_chars = set(''.join(english_texts))\n",
        "\n",
        "encoded_vocab = {c: i+1 for i, c in enumerate(sorted(all_encoded_chars))}\n",
        "encoded_vocab['<PAD>'] = 0\n",
        "\n",
        "english_vocab = {c: i+1 for i, c in enumerate(sorted(all_english_chars))}\n",
        "english_vocab['<PAD>'] = 0\n",
        "\n",
        "rev_english_vocab = {i: c for c, i in english_vocab.items()}\n",
        "\n",
        "sos_token = 71\n",
        "eos_token = 70\n",
        "\n",
        "print(f\"Encoded vocab: {len(encoded_vocab)}, English vocab: {len(english_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_seq(texts, vocab):\n",
        "    return [[vocab.get(c, 0) for c in t] for t in texts]\n",
        "\n",
        "encoded_seqs = text_to_seq(encoded_texts, encoded_vocab)\n",
        "english_seqs = text_to_seq(english_texts, english_vocab)\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_seqs, tgt_seqs, sos_token, eos_token, max_len=512):\n",
        "        self.src_seqs = src_seqs\n",
        "        self.tgt_seqs = tgt_seqs\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.src_seqs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        src_seq = self.src_seqs[idx][:self.max_len]\n",
        "        tgt_seq = self.tgt_seqs[idx][:self.max_len-2]\n",
        "        src = torch.LongTensor(src_seq)\n",
        "        tgt = torch.LongTensor([self.sos_token] + tgt_seq + [self.eos_token])\n",
        "        return src, tgt\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "dataset = TranslationDataset(encoded_seqs, english_seqs, sos_token, eos_token)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 15\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "        \n",
        "        logits = model(src, tgt_input)\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_output.reshape(-1))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "            logits = model(src, tgt_input)\n",
        "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_output.reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = validate(model, val_loader)\n",
        "    \n",
        "    old_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step(val_loss)\n",
        "    new_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_translation.pth')\n",
        "        print(f\"✓ Epoch {epoch+1}/{NUM_EPOCHS} - Train: {train_loss:.4f}, Val: {val_loss:.4f} [SAVED]\")\n",
        "    else:\n",
        "        print(f\"  Epoch {epoch+1}/{NUM_EPOCHS} - Train: {train_loss:.4f}, Val: {val_loss:.4f}\")\n",
        "    \n",
        "    if old_lr != new_lr:\n",
        "        print(f\"  → LR: {old_lr:.6f} → {new_lr:.6f}\")\n",
        "\n",
        "print(f\"\\nBest val loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate(model, src_text, encoded_vocab, rev_english_vocab, sos_token, eos_token, max_len=512):\n",
        "    model.eval()\n",
        "    src_seq = [encoded_vocab.get(c, 0) for c in src_text]\n",
        "    src_tensor = torch.LongTensor(src_seq).unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        batch_size, seq_len = src_tensor.size()\n",
        "        pos_idx = torch.arange(seq_len, device=device).unsqueeze(0)\n",
        "        pos_idx = torch.clamp(pos_idx, max=511)\n",
        "        pos_embedded = model.pos_embedding(pos_idx)\n",
        "        embedded_src = model.src_embedding(src_tensor) + pos_embedded\n",
        "        _, (hidden, cell) = model.encoder(embedded_src)\n",
        "    \n",
        "    decoded = [sos_token]\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.LongTensor([decoded]).to(device)\n",
        "        with torch.no_grad():\n",
        "            embedded_tgt = model.tgt_embedding(tgt_tensor)\n",
        "            outputs, (hidden, cell) = model.decoder(embedded_tgt, (hidden, cell))\n",
        "            logits = model.fc(outputs)\n",
        "        \n",
        "        next_token = logits[0, -1].argmax().item()\n",
        "        if next_token == eos_token:\n",
        "            break\n",
        "        decoded.append(next_token)\n",
        "    \n",
        "    return ''.join([rev_english_vocab.get(i, '') for i in decoded[1:] if i != 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Training Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_translation.pth'))\n",
        "\n",
        "print(\"Testing on training examples:\\n\")\n",
        "for i in range(3):\n",
        "    enc = encoded_texts[i][:80]\n",
        "    exp = english_texts[i][:80]\n",
        "    pred = translate(model, encoded_texts[i], encoded_vocab, rev_english_vocab, sos_token, eos_token)\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Encoded:  {enc}...\")\n",
        "    print(f\"Expected: {exp}...\")\n",
        "    print(f\"Predicted: {pred[:80]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Translate Test Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('test-part2.txt', 'r', encoding='utf-8') as f:\n",
        "    test_phrases = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(f\"Translating {len(test_phrases)} phrases...\\n\")\n",
        "\n",
        "translations = []\n",
        "for i, phrase in enumerate(test_phrases):\n",
        "    translation = translate(model, phrase, encoded_vocab, rev_english_vocab, sos_token, eos_token)\n",
        "    translations.append(translation)\n",
        "    print(f\"{i+1}. {translation}\")\n",
        "\n",
        "# Save\n",
        "with open('44_XLR8_part2.txt', 'w', encoding='utf-8') as f:\n",
        "    for t in translations:\n",
        "        f.write(t + '\\n')\n",
        "\n",
        "print(f\"\\n✓ Saved: 44_XLR8_part2.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. ✅ Share this notebook with all 6 TAs\n",
        "2. ✅ Submit `44_XLR8_part2.txt`\n",
        "\n",
        "### TA Kaggle IDs:\n",
        "- adyabhat\n",
        "- anaghakini  \n",
        "- namitaachyuth\n",
        "- tejasvenugopalan\n",
        "- shusrith\n",
        "- siddhiz"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
